#!/run/current-system/sw/bin/bash
# setup-machine.sh - Automated new machine setup for Hydrix
#
# This script automatically:
# 1. Detects hostname and CPU platform (Intel/AMD)
# 2. Creates machine profile (minimal, based on zephyrus template)
# 3. Generates consolidated config with VFIO/specialisations
# 4. Updates flake.nix with new machine entry
# 5. Builds router VM image
# 6. Generates autostart script
# 7. Git adds generated files
#
# Usage: ./scripts/setup-machine.sh
# No manual input required - fully automatic

set -euo pipefail

readonly SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
readonly PROJECT_DIR="$(dirname "$SCRIPT_DIR")"
readonly GENERATED_DIR="$PROJECT_DIR/generated"

# Logging
log() { echo "[$(date +%H:%M:%S)] $*"; }
error() { echo "[ERROR] $*" >&2; exit 1; }
success() { echo "[SUCCESS] $*"; }
warn() { echo "[WARN] $*"; }

# ========== AUTO-DETECTION FUNCTIONS ==========

detect_hostname() {
    local hostname
    hostname=$(hostnamectl hostname 2>/dev/null || hostname)

    # Sanitize hostname for use in Nix identifiers
    # Remove any characters that aren't alphanumeric or hyphen
    hostname=$(echo "$hostname" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9-]//g')

    if [[ -z "$hostname" ]]; then
        error "Could not detect hostname"
    fi

    echo "$hostname"
}

detect_cpu_platform() {
    # Returns "intel" or "amd" based on CPU vendor
    local cpu_vendor
    cpu_vendor=$(grep -m1 "vendor_id" /proc/cpuinfo | awk '{print $3}')

    case "$cpu_vendor" in
        GenuineIntel)
            echo "intel"
            ;;
        AuthenticAMD)
            echo "amd"
            ;;
        *)
            warn "Unknown CPU vendor: $cpu_vendor - defaulting to intel"
            echo "intel"
            ;;
    esac
}

get_iommu_param() {
    local platform="$1"
    case "$platform" in
        intel)
            echo "intel_iommu=on"
            ;;
        amd)
            echo "amd_iommu=on"
            ;;
        *)
            echo "intel_iommu=on"
            ;;
    esac
}

# ========== PREREQUISITE CHECKS ==========

check_prerequisites() {
    log "Checking prerequisites..."

    if [[ $EUID -eq 0 ]]; then
        error "Don't run this as root"
    fi

    local missing=()
    for cmd in nix git jq; do
        if ! command -v "$cmd" >/dev/null 2>&1; then
            missing+=("$cmd")
        fi
    done

    if [[ ${#missing[@]} -gt 0 ]]; then
        error "Missing dependencies: ${missing[*]}"
    fi

    # Check we're in the Hydrix directory
    if [[ ! -f "$PROJECT_DIR/flake.nix" ]]; then
        error "flake.nix not found - are you in the Hydrix directory?"
    fi

    log "Prerequisites OK"
}

# ========== CHECK IF MACHINE ALREADY EXISTS ==========

check_machine_exists() {
    local machine_name="$1"
    local flake_path="$PROJECT_DIR/flake.nix"

    if grep -q "^[[:space:]]*${machine_name}[[:space:]]*=" "$flake_path"; then
        return 0  # exists
    fi
    return 1  # does not exist
}

# ========== HARDWARE DETECTION ==========

run_hardware_detection() {
    log "Running hardware detection..."

    cd "$PROJECT_DIR"

    if [[ -x "$SCRIPT_DIR/hardware-identify.sh" ]]; then
        if ! "$SCRIPT_DIR/hardware-identify.sh"; then
            error "Hardware detection failed"
        fi
    else
        error "hardware-identify.sh not found or not executable"
    fi

    if [[ ! -f "$PROJECT_DIR/hardware-results.env" ]]; then
        error "Hardware detection did not produce results"
    fi

    source "$PROJECT_DIR/hardware-results.env"

    if [[ ${COMPATIBILITY_SCORE:-0} -lt 5 ]]; then
        warn "Hardware compatibility score is low (${COMPATIBILITY_SCORE:-0}/10)"
        warn "Router VM passthrough may not work reliably"
    fi

    log "Hardware: $PRIMARY_INTERFACE ($PRIMARY_ID) on $PRIMARY_PCI"
    log "Driver: $PRIMARY_DRIVER"
    log "Compatibility: ${COMPATIBILITY_SCORE:-0}/10"
}

# ========== GENERATE MACHINE PROFILE ==========

generate_machine_profile() {
    local machine_name="$1"
    local profile_path="$PROJECT_DIR/profiles/machines/${machine_name}.nix"

    log "Generating machine profile: ${machine_name}.nix"

    mkdir -p "$PROJECT_DIR/profiles/machines"

    # Check if profile already exists
    if [[ -f "$profile_path" ]]; then
        warn "Machine profile already exists: $profile_path"
        warn "Skipping profile generation"
        return
    fi

    cat > "$profile_path" << PROFILEEOF
# ${machine_name} - Machine-specific configuration
# Auto-generated by setup-machine.sh on $(date)
#
# This is a minimal machine profile. Add hardware-specific settings as needed:
# - GPU configuration (NVIDIA/AMD)
# - Power management
# - Vendor-specific tools
# - Custom kernel parameters

{ config, pkgs, lib, ... }:

{
  # Import generated configuration (VFIO + specialisations)
  imports = [
    ../../generated/modules/${machine_name}-consolidated.nix

    # Theming system (dynamic for host machine)
    ../../modules/theming/dynamic.nix
    ../../modules/desktop/xinitrc.nix
  ];

  # Override hostname for this machine
  networking.hostName = lib.mkForce "${machine_name}";

  # ========== ADD MACHINE-SPECIFIC PACKAGES HERE ==========
  # environment.systemPackages = with pkgs; [
  #   # Example: NVIDIA tools
  #   # nvtopPackages.full
  #   # cudatoolkit
  #
  #   # Example: Power management
  #   # powertop
  #   # acpi
  # ];

  # ========== ADD HARDWARE-SPECIFIC SETTINGS HERE ==========
  # Examples:
  #
  # # NVIDIA GPU
  # hardware.nvidia = {
  #   modesetting.enable = true;
  #   # ...
  # };
  #
  # # Power management
  # services.tlp.enable = true;
  #
  # # Bluetooth
  # hardware.bluetooth.enable = true;
}
PROFILEEOF

    success "Machine profile created: $profile_path"
}

# ========== GENERATE CONSOLIDATED CONFIG ==========

generate_consolidated_config() {
    local machine_name="$1"
    local cpu_platform="$2"

    log "Generating consolidated configuration..."

    source "$PROJECT_DIR/hardware-results.env"

    mkdir -p "$GENERATED_DIR/modules"

    local output_file="$GENERATED_DIR/modules/${machine_name}-consolidated.nix"
    local iommu_param
    iommu_param=$(get_iommu_param "$cpu_platform")
    local username="${USER:-$(whoami)}"

    log "  Machine: $machine_name"
    log "  CPU Platform: $cpu_platform"
    log "  IOMMU Param: $iommu_param"
    log "  WiFi Device: $PRIMARY_ID ($PRIMARY_PCI)"
    log "  Driver: $PRIMARY_DRIVER"

    cat > "$output_file" << CONSOLIDATEDEOF
# Consolidated Machine Configuration for ${machine_name}
# Generated by setup-machine.sh on $(date)
# Contains: Conditional VFIO passthrough + Router services + Maximalism specialization
# CPU Platform: ${cpu_platform}
# Hardware: ${PRIMARY_ID} (${PRIMARY_PCI})
# Base mode: Normal WiFi/network operation (VFIO disabled)
# Router/Maximalism modes: VFIO passthrough enabled for VM isolation

{ config, lib, pkgs, ... }:
let
  # Detect if we're in router or maximalism mode
  isRouterMode = config.system.nixos.label == "router-setup" || config.system.nixos.label == "maximalism-setup";
in
{
  # ===== VFIO PASSTHROUGH CONFIGURATION (Conditional - only for router/maximalism) =====
  boot.kernelParams = lib.mkIf isRouterMode [
    "${iommu_param}"
    "iommu=pt"
    "vfio-pci.ids=${PRIMARY_ID}"
  ];

  boot.kernelModules = lib.mkIf isRouterMode [ "vfio" "vfio_iommu_type1" "vfio_pci" ];

  # Enable libvirtd (always available for VM management, but VFIO only in router modes)
  virtualisation.libvirtd = {
    enable = true;
    qemu = {
      package = lib.mkForce pkgs.qemu_kvm;
      runAsRoot = true;
      swtpm.enable = true;
      ovmf = {
        enable = true;
        packages = [ pkgs.OVMFFull.fd ];
      };
    };
  };

  # ===== BOOT CONFIGURATION - Default to Maximalism =====
  # This ensures the system boots into maximalism mode by default
  # so router VM autostart works without manual bootloader selection
  boot.loader.grub.default = "saved";
  boot.loader.grub.extraConfig = ''
    set default="NixOS - maximalism-setup"
  '';

  # ===== ROUTER SPECIALIZATION =====
  specialisation.router.configuration = {
    system.nixos.label = lib.mkForce "router-setup";

    # Router mode: WiFi blacklisted for passthrough
    boot.blacklistedKernelModules = [ "${PRIMARY_DRIVER}" ];

    # Router networking bridges
    networking.bridges.virbr1.interfaces = [];
    networking.interfaces.virbr1 = {
      ipv4.addresses = [{
        address = "192.168.100.1";
        prefixLength = 24;
      }];
    };

    networking.bridges.virbr2.interfaces = [];
    networking.interfaces.virbr2 = {
      ipv4.addresses = [{
        address = "192.168.101.1";
        prefixLength = 24;
      }];
    };

    networking.bridges.virbr3.interfaces = [];
    networking.interfaces.virbr3 = {
      ipv4.addresses = [{
        address = "192.168.102.1";
        prefixLength = 24;
      }];
    };

    networking.bridges.virbr4.interfaces = [];
    networking.interfaces.virbr4 = {
      ipv4.addresses = [{
        address = "192.168.103.1";
        prefixLength = 24;
      }];
    };

    networking.bridges.virbr5.interfaces = [];
    networking.interfaces.virbr5 = {
      ipv4.addresses = [{
        address = "192.168.104.1";
        prefixLength = 24;
      }];
    };

    # Default route through router VM
    networking.defaultGateway = {
      address = "192.168.100.253";
      interface = "virbr1";
    };

    # Firewall rules for bridge networking
    networking.firewall = {
      extraCommands = ''
        # Management bridge (virbr1)
        iptables -A FORWARD -i virbr1 -j ACCEPT
        iptables -A FORWARD -o virbr1 -j ACCEPT
        iptables -t nat -A POSTROUTING -s 192.168.100.0/24 -j MASQUERADE

        # VM network bridges (virbr2-virbr5)
        iptables -A FORWARD -i virbr2 -j ACCEPT
        iptables -A FORWARD -o virbr2 -j ACCEPT
        iptables -A FORWARD -i virbr3 -j ACCEPT
        iptables -A FORWARD -o virbr3 -j ACCEPT
        iptables -A FORWARD -i virbr4 -j ACCEPT
        iptables -A FORWARD -o virbr4 -j ACCEPT
        iptables -A FORWARD -i virbr5 -j ACCEPT
        iptables -A FORWARD -o virbr5 -j ACCEPT

        # Allow inter-bridge communication through router VM
        iptables -A FORWARD -i virbr2 -o virbr1 -j ACCEPT
        iptables -A FORWARD -i virbr1 -o virbr2 -j ACCEPT
        iptables -A FORWARD -i virbr3 -o virbr1 -j ACCEPT
        iptables -A FORWARD -i virbr1 -o virbr3 -j ACCEPT
        iptables -A FORWARD -i virbr4 -o virbr1 -j ACCEPT
        iptables -A FORWARD -i virbr1 -o virbr4 -j ACCEPT
        iptables -A FORWARD -i virbr5 -o virbr1 -j ACCEPT
        iptables -A FORWARD -i virbr1 -o virbr5 -j ACCEPT
      '';
      trustedInterfaces = [ "virbr1" "virbr2" "virbr3" "virbr4" "virbr5" ];
    };

    # Router VM autostart service
    systemd.services.router-vm-autostart = {
      description = "Auto-start router VM with WiFi passthrough";
      after = [
        "libvirtd.service"
        "network.target"
        "network-online.target"
      ];
      wants = [ "libvirtd.service" "network-online.target" ];
      wantedBy = [ "multi-user.target" ];
      serviceConfig = {
        Type = "oneshot";
        ExecStart = "/home/${username}/Hydrix/generated/scripts/autostart-router-vm.sh";
        RemainAfterExit = true;
        User = "root";
        TimeoutStartSec = "120s";
        Environment = "PATH=/run/current-system/sw/bin:/run/current-system/sw/sbin";
      };
    };

    # Router status command
    environment.systemPackages = with pkgs; lib.mkAfter [
      virt-manager
      (writeShellScriptBin "router-status" ''
        echo "ROUTER MODE Status"
        echo "=================="
        echo ""

        echo "Router VM Status:"
        sudo virsh list --all | grep router || echo "Router VM not found"
        echo ""

        echo "Network Status:"
        echo "  Router Bridge: \$(ip link show virbr1 2>/dev/null | grep -o 'state [A-Z]*' || echo 'DOWN')"
        echo "  Default Route: \$(ip route | grep default | awk '{print \$5}' | head -1 || echo 'unknown')"
        echo ""

        echo "Hardware Status:"
        echo "  WiFi Blacklisted: \$(lsmod | grep ${PRIMARY_DRIVER} > /dev/null && echo 'NO (loaded)' || echo 'YES (blacklisted)')"
        echo "  PCI Device: ${PRIMARY_PCI} (${PRIMARY_ID})"
        echo ""

        echo "Quick Actions:"
        echo "  Router Console: sudo virsh console router-vm-passthrough"
        echo "  VM Manager:     virt-manager"
        echo "  Switch to base: sudo nixos-rebuild switch --flake ~/Hydrix#${machine_name}"
      '')
    ];
  };

  # ===== MAXIMALISM SPECIALIZATION =====
  specialisation.maximalism.configuration = {
    system.nixos.label = lib.mkForce "maximalism-setup";

    # Router configuration (inherited from router specialization)
    boot.blacklistedKernelModules = [ "${PRIMARY_DRIVER}" ];

    # Router networking bridges (duplicated for maximalism)
    networking.bridges.virbr1.interfaces = [];
    networking.interfaces.virbr1 = {
      ipv4.addresses = [{
        address = "192.168.100.1";
        prefixLength = 24;
      }];
    };

    networking.bridges.virbr2.interfaces = [];
    networking.interfaces.virbr2 = {
      ipv4.addresses = [{
        address = "192.168.101.1";
        prefixLength = 24;
      }];
    };

    networking.bridges.virbr3.interfaces = [];
    networking.interfaces.virbr3 = {
      ipv4.addresses = [{
        address = "192.168.102.1";
        prefixLength = 24;
      }];
    };

    networking.bridges.virbr4.interfaces = [];
    networking.interfaces.virbr4 = {
      ipv4.addresses = [{
        address = "192.168.103.1";
        prefixLength = 24;
      }];
    };

    networking.bridges.virbr5.interfaces = [];
    networking.interfaces.virbr5 = {
      ipv4.addresses = [{
        address = "192.168.104.1";
        prefixLength = 24;
      }];
    };

    # Default route through router VM
    networking.defaultGateway = {
      address = "192.168.100.253";
      interface = "virbr1";
    };

    # Firewall rules for bridge networking (duplicated)
    networking.firewall = {
      extraCommands = ''
        # Management bridge (virbr1)
        iptables -A FORWARD -i virbr1 -j ACCEPT
        iptables -A FORWARD -o virbr1 -j ACCEPT
        iptables -t nat -A POSTROUTING -s 192.168.100.0/24 -j MASQUERADE

        # VM network bridges (virbr2-virbr5)
        iptables -A FORWARD -i virbr2 -j ACCEPT
        iptables -A FORWARD -o virbr2 -j ACCEPT
        iptables -A FORWARD -i virbr3 -j ACCEPT
        iptables -A FORWARD -o virbr3 -j ACCEPT
        iptables -A FORWARD -i virbr4 -j ACCEPT
        iptables -A FORWARD -o virbr4 -j ACCEPT
        iptables -A FORWARD -i virbr5 -j ACCEPT
        iptables -A FORWARD -o virbr5 -j ACCEPT

        # Allow inter-bridge communication
        iptables -A FORWARD -i virbr2 -o virbr1 -j ACCEPT
        iptables -A FORWARD -i virbr1 -o virbr2 -j ACCEPT
        iptables -A FORWARD -i virbr3 -o virbr1 -j ACCEPT
        iptables -A FORWARD -i virbr1 -o virbr3 -j ACCEPT
        iptables -A FORWARD -i virbr4 -o virbr1 -j ACCEPT
        iptables -A FORWARD -i virbr1 -o virbr4 -j ACCEPT
        iptables -A FORWARD -i virbr5 -o virbr1 -j ACCEPT
        iptables -A FORWARD -i virbr1 -o virbr5 -j ACCEPT
      '';
      trustedInterfaces = [ "virbr1" "virbr2" "virbr3" "virbr4" "virbr5" ];
    };

    # Router VM autostart service (from router specialization)
    systemd.services.router-vm-autostart = {
      description = "Auto-start router VM with WiFi passthrough";
      after = [
        "libvirtd.service"
        "network.target"
        "network-online.target"
      ];
      wants = [ "libvirtd.service" "network-online.target" ];
      wantedBy = [ "multi-user.target" ];
      serviceConfig = {
        Type = "oneshot";
        ExecStart = "/home/${username}/Hydrix/generated/scripts/autostart-router-vm.sh";
        RemainAfterExit = true;
        User = "root";
        TimeoutStartSec = "120s";
        Environment = "PATH=/run/current-system/sw/bin:/run/current-system/sw/sbin";
      };
    };

    # Enhanced status command for maximalism mode
    environment.systemPackages = with pkgs; lib.mkAfter [
      virt-manager

      (writeShellScriptBin "maximalism-status" ''
        echo "MAXIMALISM MODE Status"
        echo "======================"
        echo ""

        echo "Router VM Status:"
        sudo virsh list --all | grep router || echo "Router VM not found"
        echo ""

        echo "Network Status:"
        echo "  Router Bridge: \$(ip link show virbr1 2>/dev/null | grep -o 'state [A-Z]*' || echo 'DOWN')"
        echo "  Default Route: \$(ip route | grep default | awk '{print \$5}' | head -1 || echo 'unknown')"
        echo ""

        echo "Quick Actions:"
        echo "  Router Console:           sudo virsh console router-vm-passthrough"
        echo "  VM Manager:               virt-manager"
        echo "  Switch to router:         sudo nixos-rebuild switch --flake ~/Hydrix#${machine_name} --specialisation router"
        echo "  Switch to base:           sudo nixos-rebuild switch --flake ~/Hydrix#${machine_name}"
      '')
    ];
  };

  # ===== BASE CONFIGURATION (Always Enabled) =====
  environment.systemPackages = with pkgs; lib.mkAfter [
    virt-manager
    virt-viewer
    libvirt
    qemu
    OVMF
    spice-gtk

    # Status command for current mode detection
    (writeShellScriptBin "vm-status" ''
      echo "${machine_name} VM Status"
      echo "======================"
      echo ""

      # Detect current specialisation
      if [[ -L /run/current-system/specialisation ]]; then
        ACTIVE_SPEC=\$(readlink /run/current-system/specialisation | xargs basename 2>/dev/null || echo "none")
        echo "Current Mode: \$ACTIVE_SPEC"
      else
        echo "Current Mode: base (no specialisation active)"
      fi
      echo ""

      echo "Available Specialisations:"
      echo "  base        - Normal laptop mode (WiFi enabled)"
      echo "  router      - Router VM only (WiFi passthrough)"
      echo "  maximalism  - Router + Pentest VMs (full setup)"
      echo ""

      echo "Quick Switch Commands:"
      echo "  sudo nixos-rebuild switch --flake ~/Hydrix#${machine_name}"
      echo "  sudo nixos-rebuild switch --flake ~/Hydrix#${machine_name} --specialisation router"
      echo "  sudo nixos-rebuild switch --flake ~/Hydrix#${machine_name} --specialisation maximalism"
      echo ""

      # Show running VMs regardless of mode
      echo "Currently Running VMs:"
      sudo virsh list --name 2>/dev/null | grep -v '^\$' || echo "  No VMs running"
    '')
  ];
}
CONSOLIDATEDEOF

    success "Consolidated configuration generated: $output_file"
}

# ========== UPDATE FLAKE.NIX ==========

update_flake() {
    local machine_name="$1"
    local flake_path="$PROJECT_DIR/flake.nix"

    log "Updating flake.nix with ${machine_name} configuration..."

    # Check if machine configuration already exists
    if check_machine_exists "$machine_name"; then
        warn "Machine '$machine_name' already exists in flake.nix"
        warn "Skipping flake update"
        return
    fi

    # Create the new configuration block
    local new_config
    new_config=$(cat << FLAKEENTRY

      # ${machine_name} - Auto-generated configuration
      # Build with: ./nixbuild.sh (hostname: ${machine_name})
      ${machine_name} = nixpkgs.lib.nixosSystem {
        system = "x86_64-linux";
        modules = [
          { nixpkgs.config.allowUnfree = true; }
          { nixpkgs.overlays = [ overlay-unstable ]; }
          nix-index-database.nixosModules.nix-index
          home-manager.nixosModules.home-manager

          # Base system configuration
          ./modules/base/configuration.nix
          ./modules/base/hardware-config.nix

          # Machine-specific configuration (imports generated consolidated module)
          ./profiles/machines/${machine_name}.nix

          # Core functionality modules
          ./modules/wm/i3.nix
          ./modules/shell/packages.nix
          ./modules/base/services.nix
          ./modules/base/users.nix
          ./modules/theming/colors.nix
          ./modules/base/virt.nix
          ./modules/base/audio.nix
          ./modules/desktop/firefox.nix
        ];
      };
FLAKEENTRY
)

    # Find the line with "nixosConfigurations = {" and add new config after it
    local temp_file
    temp_file=$(mktemp)
    local added=false

    while IFS= read -r line; do
        echo "$line" >> "$temp_file"

        # After "nixosConfigurations = {", add the new machine config
        if [[ "$line" =~ "nixosConfigurations = {" ]] && [[ "$added" == false ]]; then
            echo "$new_config" >> "$temp_file"
            added=true
        fi
    done < "$flake_path"

    if [[ "$added" == true ]]; then
        mv "$temp_file" "$flake_path"
        success "Flake configuration updated with ${machine_name}"
    else
        rm "$temp_file"
        error "Could not find insertion point in flake.nix"
    fi
}

# ========== BUILD ROUTER VM ==========

build_router_vm() {
    log "Building router VM image..."

    cd "$PROJECT_DIR"

    # Check if router VM already built
    if [[ -f "router-vm-result/nixos.qcow2" ]]; then
        local size
        size=$(du -h router-vm-result/nixos.qcow2 | cut -f1)
        log "Router VM already built: $size"
        log "Use --force-rebuild to rebuild"
        return
    fi

    log "This may take several minutes..."

    if ! nix build .#router-vm-qcow --out-link router-vm-result; then
        error "Router VM build failed"
    fi

    if [[ -f "router-vm-result/nixos.qcow2" ]]; then
        local size
        size=$(du -h router-vm-result/nixos.qcow2 | cut -f1)
        success "Router VM built: $size"
    else
        error "Router VM build failed - no qcow2 found"
    fi
}

# ========== GENERATE AUTOSTART SCRIPT ==========

generate_autostart_script() {
    log "Generating autostart script..."

    mkdir -p "$GENERATED_DIR/scripts"

    local script_path="$GENERATED_DIR/scripts/autostart-router-vm.sh"

    cat > "$script_path" << 'AUTOSTARTEOF'
#!/run/current-system/sw/bin/bash
set -euo pipefail

readonly VM_NAME="router-vm-passthrough"
log() { echo "[$(date +%H:%M:%S)] Router Autostart: $*"; }

VIRSH="/run/current-system/sw/bin/virsh"
SYSTEMCTL="/run/current-system/sw/bin/systemctl"

log "Starting router VM autostart process..."

if ! $SYSTEMCTL is-active --quiet libvirtd; then
    log "Starting libvirtd service..."
    $SYSTEMCTL start libvirtd
    sleep 3
fi

sleep 2

if ! $VIRSH --connect qemu:///system list --all | grep -q "$VM_NAME"; then
    log "ERROR: Router VM '$VM_NAME' not found"
    log "Please run deploy-router-vm.sh first"
    exit 1
fi

vm_state=$($VIRSH --connect qemu:///system list --all | grep "$VM_NAME" | awk '{print $3}' || echo "unknown")
log "Router VM current state: $vm_state"

case "$vm_state" in
    "running")
        log "Router VM is already running"
        ;;
    "paused")
        log "Router VM is paused, resuming..."
        if $VIRSH --connect qemu:///system resume "$VM_NAME" 2>&1; then
            log "Router VM resumed successfully"
            sleep 2
        else
            sleep 1
            current_state=$($VIRSH --connect qemu:///system domstate "$VM_NAME" || echo "unknown")
            if [ "$current_state" = "running" ]; then
                log "Router VM transitioned to running state"
            else
                log "ERROR: Failed to resume router VM (current state: $current_state)"
                exit 1
            fi
        fi
        ;;
    "shut"|"shutoff")
        log "Starting router VM..."
        if $VIRSH --connect qemu:///system start "$VM_NAME" 2>&1; then
            log "Router VM started successfully"
            sleep 2
        else
            sleep 1
            current_state=$($VIRSH --connect qemu:///system domstate "$VM_NAME" || echo "unknown")
            if [ "$current_state" = "running" ]; then
                log "Router VM transitioned to running state"
            else
                log "ERROR: Failed to start router VM (current state: $current_state)"
                exit 1
            fi
        fi
        ;;
    *)
        log "Router VM in unexpected state: $vm_state"
        log "Attempting to start anyway..."
        if $VIRSH --connect qemu:///system start "$VM_NAME" 2>&1; then
            log "Router VM started despite unexpected state"
            sleep 2
        else
            sleep 1
            current_state=$($VIRSH --connect qemu:///system domstate "$VM_NAME" || echo "unknown")
            if [ "$current_state" = "running" ]; then
                log "Router VM transitioned to running state"
            else
                log "ERROR: Failed to start router VM (current state: $current_state)"
                exit 1
            fi
        fi
        ;;
esac

if $VIRSH --connect qemu:///system list | grep -q "$VM_NAME.*running"; then
    log "[+] Router VM is running and ready"
    log "[+] Management interface: 192.168.100.253"
else
    log "[!] Router VM startup verification failed"
    exit 1
fi

log "Router VM autostart completed successfully"
AUTOSTARTEOF

    chmod +x "$script_path"
    success "Autostart script generated: $script_path"
}

# ========== DEPLOY ROUTER VM ==========

deploy_router_vm() {
    log "Deploying router VM to libvirt..."

    source "$PROJECT_DIR/hardware-results.env"

    local vm_name="router-vm-passthrough"
    local vm_image_source="$PROJECT_DIR/router-vm-result/nixos.qcow2"
    local vm_image_dest="/var/lib/libvirt/images/$vm_name.qcow2"

    if [[ ! -f "$vm_image_source" ]]; then
        error "Router VM image not found: $vm_image_source"
    fi

    # Check if VM already exists
    if sudo virsh --connect qemu:///system list --all 2>/dev/null | grep -q "$vm_name"; then
        log "Router VM already deployed - removing for fresh deploy"
        sudo virsh --connect qemu:///system destroy "$vm_name" 2>/dev/null || true
        sudo virsh --connect qemu:///system undefine "$vm_name" --nvram 2>/dev/null || true
        sudo rm -f "$vm_image_dest"
    fi

    # Copy VM image
    log "Copying VM image to libvirt storage..."
    sudo mkdir -p /var/lib/libvirt/images
    sudo cp "$vm_image_source" "$vm_image_dest"
    sudo chmod 644 "$vm_image_dest"

    # Format PCI ID for virt-install (0000:00:14.3 -> 00:14.3)
    local pci_short="${PRIMARY_PCI#0000:}"

    log "Deploying router VM with WiFi passthrough (PCI: $pci_short)..."

    # Note: This creates the VM definition but won't start it until bridges exist
    # The VM will autostart when booted into maximalism mode
    if sudo virt-install \
        --connect qemu:///system \
        --name "$vm_name" \
        --memory 2048 \
        --vcpus 2 \
        --disk "$vm_image_dest,device=disk,bus=virtio" \
        --os-variant nixos-unstable \
        --boot hd \
        --nographics \
        --network bridge=virbr1,model=virtio \
        --network bridge=virbr2,model=virtio \
        --network bridge=virbr3,model=virtio \
        --network bridge=virbr4,model=virtio \
        --network bridge=virbr5,model=virtio \
        --hostdev "$pci_short" \
        --noautoconsole \
        --import 2>/dev/null; then
        success "Router VM deployed with WiFi passthrough!"
    else
        log "WiFi passthrough failed (bridges may not exist yet)"
        log "Creating VM definition without passthrough - will work after reboot into maximalism"
        sudo virt-install \
            --connect qemu:///system \
            --name "$vm_name" \
            --memory 2048 \
            --vcpus 2 \
            --disk "$vm_image_dest,device=disk,bus=virtio" \
            --os-variant nixos-unstable \
            --boot hd \
            --nographics \
            --network network=default,model=virtio \
            --noautoconsole \
            --import 2>/dev/null || warn "VM definition creation deferred until after reboot"
    fi
}

# ========== GIT STAGE FILES ==========

git_stage_files() {
    local machine_name="$1"

    log "Staging generated files in git..."

    cd "$PROJECT_DIR"

    local files_to_add=(
        "generated/modules/${machine_name}-consolidated.nix"
        "profiles/machines/${machine_name}.nix"
        "generated/scripts/autostart-router-vm.sh"
        "flake.nix"
    )

    for file in "${files_to_add[@]}"; do
        if [[ -f "$file" ]]; then
            git add "$file" 2>/dev/null && log "  [+] $file" || warn "  [!] $file (could not stage)"
        fi
    done

    success "Files staged in git"
}

# ========== SHOW COMPLETION SUMMARY ==========

show_completion_summary() {
    local machine_name="$1"
    local cpu_platform="$2"

    echo ""
    success "========================================"
    success "  MACHINE SETUP COMPLETED!"
    success "========================================"
    echo ""
    echo "Configuration:"
    echo "  Machine Name: $machine_name"
    echo "  CPU Platform: $cpu_platform"
    echo ""
    echo "Generated Files:"
    echo "  [+] profiles/machines/${machine_name}.nix"
    echo "  [+] generated/modules/${machine_name}-consolidated.nix"
    echo "  [+] generated/scripts/autostart-router-vm.sh"
    echo "  [+] flake.nix (updated)"
    echo ""
    echo "Router VM:"
    if [[ -f "$PROJECT_DIR/router-vm-result/nixos.qcow2" ]]; then
        local size
        size=$(du -h "$PROJECT_DIR/router-vm-result/nixos.qcow2" | cut -f1)
        echo "  [+] Built: router-vm-result/nixos.qcow2 ($size)"
    else
        echo "  [!] Not built (run: nix build .#router-vm-qcow)"
    fi
    if sudo virsh --connect qemu:///system list --all 2>/dev/null | grep -q "router-vm-passthrough"; then
        echo "  [+] Deployed: router-vm-passthrough"
    else
        echo "  [!] Not deployed yet (will be created on first boot into maximalism)"
    fi
    echo ""
    echo "Boot Configuration:"
    echo "  [+] Default boot: maximalism-setup (router VM will autostart)"
    echo ""
    echo "========================================"
    echo "  NEXT STEPS"
    echo "========================================"
    echo ""
    echo "1. Commit the changes:"
    echo "   git commit -m 'Add ${machine_name} machine configuration'"
    echo ""
    echo "2. Rebuild the system (will configure GRUB for maximalism default):"
    echo "   sudo nixos-rebuild boot --flake ~/Hydrix#${machine_name} --impure"
    echo ""
    echo "3. Reboot into maximalism mode:"
    echo "   sudo reboot"
    echo ""
    echo "   On reboot:"
    echo "   - System boots into maximalism-setup (default)"
    echo "   - WiFi driver is blacklisted for passthrough"
    echo "   - Bridge interfaces (virbr1-5) are created"
    echo "   - Router VM autostarts with WiFi passthrough"
    echo "   - Internet via router VM on 192.168.100.253"
    echo ""
    echo "4. Future rebuilds use ./nixbuild.sh automatically"
    echo ""
    echo "5. To switch to base mode (normal WiFi on host):"
    echo "   Select 'NixOS - Default' at boot, or:"
    echo "   sudo grub-reboot 'NixOS - Default' && sudo reboot"
    echo ""
}

# ========== MAIN ==========

main() {
    echo ""
    log "========================================"
    log "  HYDRIX MACHINE SETUP"
    log "========================================"
    echo ""

    check_prerequisites

    # Auto-detect machine info
    local machine_name
    local cpu_platform

    machine_name=$(detect_hostname)
    cpu_platform=$(detect_cpu_platform)

    log "Detected hostname: $machine_name"
    log "Detected CPU platform: $cpu_platform ($(get_iommu_param "$cpu_platform"))"
    echo ""

    # Check if machine already exists
    if check_machine_exists "$machine_name"; then
        warn "Machine '$machine_name' already exists in flake.nix"
        echo ""
        read -p "Continue anyway? This will regenerate configs. [y/N]: " -r
        if [[ ! $REPLY =~ ^[Yy]$ ]]; then
            log "Setup cancelled"
            exit 0
        fi
    fi

    # Run all setup steps
    run_hardware_detection
    generate_machine_profile "$machine_name"
    generate_consolidated_config "$machine_name" "$cpu_platform"
    update_flake "$machine_name"
    build_router_vm
    generate_autostart_script
    deploy_router_vm
    git_stage_files "$machine_name"
    show_completion_summary "$machine_name" "$cpu_platform"
}

main "$@"
